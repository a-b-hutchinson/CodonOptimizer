{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import ast\n",
    "import pandas as pd\n",
    "import Bio\n",
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "from time import sleep\n",
    "from time import monotonic\n",
    "from orffinder import orffinder\n",
    "import optipyzer\n",
    "from Bio.Restriction.Restriction import RestrictionBatch\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "import json\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkPeptides(entry) -> dict:\n",
    "\n",
    "    transit_present = False\n",
    "    signal_present = False\n",
    "    removal_regions = []\n",
    "    for i in entry['features']:\n",
    "        if 'Transit' in i['type']:\n",
    "            transit_present = True\n",
    "        if 'Signal' in i['type']:\n",
    "            signal_present = True\n",
    "        removal_regions.append([i['location']['start']['value'], i['location']['end']['value']])\n",
    "\n",
    "    return {'transit_peptide': transit_present, 'signal_peptide': signal_present, 'removed_regions': removal_regions}\n",
    "    \n",
    "\n",
    "def getUniprotInfo(id) -> dict:\n",
    "\n",
    "    params = {\n",
    "        'query': id,\n",
    "        'fields': ['xref_refseq', 'sequence', 'ft_signal', 'ft_transit']\n",
    "    }\n",
    "\n",
    "    print(f'Processing [{id}]')\n",
    "\n",
    "    res = requests.get(f'https://rest.uniprot.org/uniprotkb/{id}.fasta')\n",
    "    fasta = res.content.decode('utf-8')\n",
    "    if fasta == \"Error messages\\nThe 'accession' value has invalid format. It should be a valid UniProtKB accession\":\n",
    "        print('Issue with uniprot ID. Try removing isoform.')\n",
    "    uniprotValue = ''.join(fasta.split('\\n')[1:])\n",
    "    les_nam = fasta[re.search('\\\\|.*\\\\|', fasta).end():]\n",
    "    gene_symbol = re.search('(GN=.*? )',fasta)[0][3:].strip()\n",
    "    name = re.search(' [A-Za-z0-9s][^ ]*', les_nam)[0][1:]\n",
    "\n",
    "    response = requests.get('https://rest.uniprot.org/uniprotkb/search', params=params)\n",
    "    try:\n",
    "        entry = ast.literal_eval(str(response.content.decode('utf-8')))['results'][0]\n",
    "    except ValueError as e:\n",
    "        print(e, '\\nAttempting to reprocess...')\n",
    "        entry = ast.literal_eval(str(json.loads(response.content.decode('utf-8'))))['results'][0]\n",
    "    potential_ids = pd.json_normalize(entry)['uniProtKBCrossReferences'][0]\n",
    "    sequence_length = entry['sequence']['length']\n",
    "    if len(entry['features']) > 0:\n",
    "        peptides = checkPeptides(entry)\n",
    "        transit_peptide = peptides['transit_peptide']\n",
    "        signal_peptide = peptides['signal_peptide']\n",
    "        removed_regions = peptides['removed_regions']\n",
    "    else:\n",
    "        transit_peptide, signal_peptide, removed_regions = False, False, pd.NA\n",
    "\n",
    "    results = {\n",
    "        'uniprotValue': uniprotValue,\n",
    "        'potential_ids': potential_ids,\n",
    "        'sequence_length': sequence_length,\n",
    "        'gene_symbol': gene_symbol,\n",
    "        'name': name,\n",
    "        'transit_peptide': transit_peptide,\n",
    "        'signal_peptide': signal_peptide,\n",
    "        'removed_regions': removed_regions\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchAmino(uniprotValue, potential_ids) -> list:\n",
    "    if potential_ids == None:\n",
    "        print('No potential ids provided.')\n",
    "        return 0\n",
    "    \n",
    "    pt_ids = [i['properties'][0]['value'] for i in potential_ids]\n",
    "    potential_ids = [i.split('.')[0] for i in pt_ids] + potential_ids\n",
    "\n",
    "    for count, test in enumerate(potential_ids):\n",
    "        print(f'\\nChecking {count+1} of {len(potential_ids)} potential matches')\n",
    "        print(f'Trying to match [{test}]...')\n",
    "\n",
    "        #ENTER EMAIL HERE\n",
    "        Entrez.email = ''\n",
    "        handle = Entrez.efetch(db='nuccore', id=test, rettype='gb', retmode='text')\n",
    "        sequence = SeqIO.read(handle, \"genbank\")\n",
    "\n",
    "        for feature in sequence.features:\n",
    "            if feature.type=='CDS':\n",
    "                ncbi_match = feature.qualifiers['translation'][0]\n",
    "\n",
    "        if ncbi_match == uniprotValue:\n",
    "            print(f'Match found with [{test}]')\n",
    "            return [test, sequence, ncbi_match]\n",
    "        elif count+1 == len(potential_ids):\n",
    "            continue\n",
    "        else:\n",
    "            print('Not a match. Idling for 10 seconds...', end=' ')\n",
    "            start = monotonic()\n",
    "            while monotonic()-start < 10:\n",
    "                print('\\u2588', end=' ')\n",
    "                sleep(1.0 - ((monotonic()-start) % 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchTranslation(orfs, uniprotValue, sequence) -> str:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    orfs : dict\n",
    "    dict of orfs site from orffinder utility\n",
    "\n",
    "    uniprotValue : str\n",
    "    string from uniprot based on id\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(orfs)):\n",
    "        if uniprotValue+'*' == str(sequence.seq[orfs[i]['start']-1:orfs[i]['end']-1].translate()):\n",
    "            print(f'Matched ORF at {orfs[i]['start']-1} to {orfs[i]['end']}')\n",
    "            slice = str(sequence.seq[orfs[i]['start']-1:orfs[i]['end']-1])\n",
    "            return slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizeSlice(slice) -> str:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    slice : str\n",
    "    \n",
    "    get string of appropriate ORF section from matchTranslation\n",
    "    \"\"\"\n",
    "\n",
    "    api = optipyzer.API()\n",
    "    gblock = str(slice)\n",
    "\n",
    "    result = api.optimize(\n",
    "        seq=gblock,\n",
    "        seq_type=\"dna\",\n",
    "        weights={\"e_coli\": 1}\n",
    "    )\n",
    "\n",
    "    optimized = result['optimized_sd']\n",
    "    return optimized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findSites(optimizedCodon) -> dict:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    optimizedCodon : str\n",
    "    \n",
    "    Provider E. Coli optimized codon from optimizedSlice(). Will return dictionary\n",
    "    with whether enzyme sites are present or not.\n",
    "    \"\"\"\n",
    "    results = {'ins':[], 'outs':[]}\n",
    "    enzymes = ['BsaI', 'BbsI', 'BsmBI', 'Esp3I', 'SapI']\n",
    "    batch = RestrictionBatch()\n",
    "    for i in enzymes:\n",
    "        batch.add(i)\n",
    "\n",
    "    for i in enzymes:\n",
    "        enzyme = batch.get(i)\n",
    "        if enzyme.site in optimizedCodon:\n",
    "            results['ins'].append(i)\n",
    "            print(f'{i} in sequence')\n",
    "        else:\n",
    "            results['outs'].append(i)\n",
    "            print(f'{i} NOT in sequence')\n",
    "\n",
    "    return results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePeptides(sequence, removal_regions) -> str:\n",
    "    iden = sequence.id\n",
    "    name = sequence.name\n",
    "    desc = sequence.description\n",
    "    sequence = str(sequence.seq)\n",
    "    sequence = list(sequence)\n",
    "    to_remove = []\n",
    "    for i in removal_regions:\n",
    "        try:\n",
    "            to_remove = to_remove + [j for j in range(i[0], i[1]*3)]\n",
    "        except TypeError as e:\n",
    "            print(e,'\\n', f'There was a problem trying to identify peptide start ({i[0]}) or stop ({i[1]})\\nRebuilding sequence...')\n",
    "            sequence = ''.join(sequence)\n",
    "            record = SeqRecord(\n",
    "                Bio.Seq.Seq('ATG' + sequence),\n",
    "                id = iden,\n",
    "                name = name,\n",
    "                description = desc\n",
    "            )\n",
    "            return record\n",
    "            \n",
    "        to_remove = list(set(to_remove))\n",
    "        to_remove.sort(reverse=True)\n",
    "\n",
    "    for i in to_remove:\n",
    "        sequence.pop(i-1)\n",
    "    \n",
    "    sequence = ''.join(sequence)\n",
    "    record = SeqRecord(\n",
    "        Bio.Seq.Seq('ATG' + sequence),\n",
    "        id = iden,\n",
    "        name = name,\n",
    "        description = desc\n",
    "    )\n",
    "\n",
    "    return record\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(df) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "    csv with uniprot_id column\n",
    "    \"\"\"\n",
    "    \n",
    "    uniprotId = []\n",
    "    name = []\n",
    "    transit_peptide = []\n",
    "    signal_peptide = []\n",
    "    removed_regions = []\n",
    "    symbols = []\n",
    "    uniprotValue = []\n",
    "    sequence_length = []\n",
    "    nih_id = []\n",
    "    full_sequence = []\n",
    "    cut_sequence = []\n",
    "    amino_sequence = []\n",
    "    orf = []\n",
    "    optimized_codon = []\n",
    "    enzymes = []\n",
    "    \n",
    "\n",
    "    for count, i in enumerate(df.uniprot_id):\n",
    "        clear_output(wait=True)\n",
    "        print(f'Checking {count+1} of {len(df.uniprot_id)}')\n",
    "        uniprotInfo = getUniprotInfo(i)\n",
    "        \n",
    "        try:\n",
    "            matchedId, sequence, amino = matchAmino(uniprotInfo['uniprotValue'], uniprotInfo['potential_ids'])\n",
    "        except:\n",
    "            uniprotValue.append(uniprotInfo['uniprotValue'])\n",
    "            sequence_length.append(uniprotInfo['sequence_length'])\n",
    "            nih_id.append(pd.NA)\n",
    "            full_sequence.append(pd.NA)\n",
    "            cut_sequence.append(pd.NA)\n",
    "            amino_sequence.append(pd.NA)\n",
    "            orf.append(pd.NA)\n",
    "            optimized_codon.append(pd.NA)\n",
    "            enzymes.append(pd.NA)\n",
    "            continue\n",
    "\n",
    "        if uniprotInfo['transit_peptide'] or uniprotInfo['signal_peptide']:\n",
    "            cut_seq = removePeptides(sequence, removal_regions=uniprotInfo['removed_regions'])\n",
    "            orfs = orffinder.getORFs(cut_seq, minimum_length=uniprotInfo['sequence_length'], remove_nested=True)\n",
    "            cut_seq = cut_seq.seq\n",
    "            cut_seq = ''.join(cut_seq)\n",
    "        else:\n",
    "            cut_seq = pd.NA\n",
    "            orfs = orffinder.getORFs(sequence, minimum_length=uniprotInfo['sequence_length'], remove_nested=True)\n",
    "        slice = matchTranslation(orfs, uniprotInfo['uniprotValue'], sequence)\n",
    "        try:\n",
    "            codon = optimizeSlice(slice)\n",
    "            enzyme_results = findSites(optimizedCodon=codon)\n",
    "        except ValueError as e:\n",
    "            print('Something\\'s wrong with the codon')\n",
    "            print(e)\n",
    "            sleep(2)\n",
    "            codon = e\n",
    "            enzyme_results = pd.NA\n",
    "        \n",
    "        uniprotId.append(i)\n",
    "        name.append(uniprotInfo['name'])\n",
    "        transit_peptide.append(uniprotInfo['transit_peptide'])\n",
    "        signal_peptide.append(uniprotInfo['signal_peptide'])\n",
    "        removed_regions.append(uniprotInfo['removed_regions'])\n",
    "        symbols.append(uniprotInfo['gene_symbol'])\n",
    "        uniprotValue.append(uniprotInfo['uniprotValue'])\n",
    "        sequence_length.append(uniprotInfo['sequence_length'])\n",
    "        nih_id.append(matchedId)\n",
    "        full_sequence.append(str(sequence.seq))\n",
    "        cut_sequence.append(cut_seq)\n",
    "        amino_sequence.append(amino)\n",
    "        orf.append(slice)\n",
    "        optimized_codon.append(codon)\n",
    "        enzymes.append(enzyme_results)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    result = pd.DataFrame([\n",
    "        uniprotId,\n",
    "        name,\n",
    "        transit_peptide,\n",
    "        signal_peptide,\n",
    "        removed_regions,\n",
    "        symbols,\n",
    "        uniprotValue,\n",
    "        sequence_length,\n",
    "        nih_id,\n",
    "        full_sequence,\n",
    "        cut_sequence,\n",
    "        amino_sequence,\n",
    "        orf,\n",
    "        optimized_codon,\n",
    "        enzymes\n",
    "    ], index=[\n",
    "        'uniprotID',\n",
    "        'name',\n",
    "        'tr_peptide',\n",
    "        'si_peptide',\n",
    "        'peptide_regions',\n",
    "        'gene',\n",
    "        'up_sequence',\n",
    "        'seq_length',\n",
    "        'nih_id',\n",
    "        'full_sequence',\n",
    "        'cut_sequence',\n",
    "        'amino_sequence',\n",
    "        'orf',\n",
    "        'optimized_codon',\n",
    "        'enzymes'\n",
    "    ])\n",
    "    \n",
    "    result=result.transpose()\n",
    "\n",
    "    for i in result.index:\n",
    "        if pd.isna(result.loc[i,'enzymes']):\n",
    "            continue\n",
    "        \n",
    "        cols = result.loc[i, 'enzymes']['ins'] + result.loc[i, 'enzymes']['outs']\n",
    "        cols.sort()\n",
    "\n",
    "    for i in cols:\n",
    "        result[i] = pd.NA\n",
    "\n",
    "    for i in result.index:\n",
    "        if pd.isna(result.loc[i, 'enzymes']):\n",
    "            continue\n",
    "\n",
    "        for j in result.loc[i, 'enzymes']['ins']:\n",
    "            result.loc[i, j] = True\n",
    "\n",
    "        for k in result.loc[i, 'enzymes']['outs']:\n",
    "            result.loc[i, k] = False\n",
    "\n",
    "    result = result.drop('enzymes', axis=1)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print('Done')\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('uniprot_ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = main(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
